---
title: "My Gradual Dive into Machine Learning"
summary: "Sharing my journey into the world of ML, starting from foundational concepts and advancing through exciting projects over time."
image: "/ml-journey.jpg"
publishedAt: "2024-12-30"
---

Machine learning wasn’t an overnight fascination for me—it was a gradual evolution. Starting with the basics of algorithms and datasets, I transitioned from simple regression models to exploring neural networks, NLP, and advanced AI techniques.

In this post, I’ll walk you through my journey, highlighting the projects that shaped my growth in ML and DL.

## The Early Days: Exploring Basics

I started with projects that helped me understand data handling, basic algorithms, and foundational ML concepts:

- **Titanic Survival Prediction**: A beginner’s data science project analyzing passenger data to predict survival using logistic regression and ensemble models. This project taught me data preprocessing, feature engineering, and evaluation metrics.
- **K-Nearest Neighbors (KNN)**: Built a simple classification model to predict outcomes based on the nearest neighbors in feature space.
- **Naive Bayes Classifier**: Explored probabilistic models to classify text, gaining insights into NLP basics.
- **Random Forest Classifier**: Combined multiple decision trees to solve classification problems, appreciating the power of ensemble learning.

These projects allowed me to solidify my understanding of regression, classification, and dataset manipulation using tools like Pandas and Matplotlib.

## Intermediate Steps: Building Momentum

Once I gained confidence in basic ML, I moved to intermediate projects, exploring diverse applications:

- **Human Emotion Detection**: A classifier to detect emotions from structured datasets, improving my understanding of feature importance.
- **SOM for Fraud Detection**: Implemented a Self-Organizing Map to detect fraudulent transactions, providing an interactive and insightful project experience.
- **Stock Price Prediction using LSTM**: Leveraged recurrent networks to model temporal patterns, with a focus on financial data.
- **Autoencoder for MNIST Dataset**: Implemented an autoencoder to compress and reconstruct images from the MNIST dataset, enhancing my understanding of unsupervised learning and neural network architectures.

These projects exposed me to time-series modeling, unsupervised learning, and the early stages of NLP.

## Exploring Creativity: Advancing to GANs and Image Generation

I then shifted my focus toward generative models, combining creativity with computation:

- **GANs for Image Generation**: Created synthetic images using Generative Adversarial Networks, diving into adversarial training.
- **Training Checkpoints**: Experimented with saving GAN training states, optimizing model performance for long sessions.
- **Image from Prompts Project**: Used Hugging Face to generate images from given prompts, exploring the intersection of NLP and computer vision.

This phase showed me the potential of ML in producing creative, visually appealing outputs.

## Delving Deeper: Advanced NLP and AI Projects

Next, I started working on advanced NLP and AI models, honing my understanding of cutting-edge techniques:

- **OCR CAPTCHA Cracker**: Combined computer vision and NLP to crack CAPTCHAs, saving models for real-world deployment.
- **Skimmer NLP Project**: Built a deep NLP model to classify sentences from research abstracts into predefined categories.
- **Fine-Tuning Large Language Models (LLMs)**: Adapted LLMs like GPT-2 for niche tasks, showcasing the adaptability of pre-trained architectures.
- **RAG for PDF Question Answering**: Developed a Retrieval-Augmented Generation (RAG) model to answer questions from PDF documents, integrating document retrieval with generative response capabilities.

These projects introduced me to deep NLP techniques, Generative AI from sequence modeling to transfer learning.

## Pushing Boundaries: Reinforcement Learning and Simulation

In the latest phase of my journey, I tackled reinforcement learning and simulation-based tasks:

- **Self-Driving Car AI**: Developed an AI agent using a softmax-based approach to navigate autonomously (used Deep Q learning).

These projects tested my ability to design agents capable of making real-time decisions in dynamic environments.

## Conclusion

From basics to breakthroughs, my ML journey has been a rewarding experience of constant learning and I hope it will continue to be so. Whether it’s regression, classification, NLP, or reinforcement learning, each project added a layer of understanding.

I invite you to explore [my ML and DL projects](https://github.com/Rohit-Sharma-RS/ML-and-DL), where I’ve shared these projects and more. Feel free to connect if you’d like to discuss machine learning—it’s a field with endless possibilities!

— Rohit